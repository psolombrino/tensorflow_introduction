{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Enabled compatitility with tensor flow 1.x\nThe tensorboard extension is already loaded. To reload it, use:\n  %reload_ext tensorboard\n"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "if tf.__version__.startswith(\"2.\"):\n",
    "  import tensorflow.compat.v1 as tf\n",
    "  tf.compat.v1.disable_v2_behavior()\n",
    "  tf.compat.v1.disable_eager_execution()\n",
    "  print(\"Enabled compatitility with tensor flow 1.x\")\n",
    "\n",
    "%load_ext tensorboard\n",
    "#%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load('training_data.npy')\n",
    "\n",
    "dataset[0:, 0] /= 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset[:,1].reshape(-1, 1)\n",
    "y = dataset[:,0].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Módelo Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, epochs, lr, print_rate=100):\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    with tf.name_scope(\"input\"):\n",
    "        x = tf.concat([x, tf.ones_like(x)], axis = 1)\n",
    "    with tf.name_scope(\"params\"):\n",
    "        params = tf.Variable(name=\"params\", initial_value = tf.zeros((2, 1), tf.float64))\n",
    "    with tf.name_scope(\"predict\"):\n",
    "        y_hat = tf.matmul(x, params)\n",
    "    with tf.name_scope(\"error\"):\n",
    "        error = 1/2 * tf.reduce_mean(tf.math.square(y - y_hat))\n",
    "    with tf.name_scope(\"gradient\"):\n",
    "        gradients = tf.gradients(error, params)\n",
    "    with tf.name_scope(\"update_model\"):\n",
    "        fit = tf.scalar_mul(-lr, gradients[0])\n",
    "        update_model = tf.assign(params, tf.add(params, fit))\n",
    "\n",
    "\n",
    "    with tf.Session() as session:\n",
    "        summary = tf.summary.scalar(name = \"error_epochs\", tensor = error)\n",
    "        writer = tf.summary.FileWriter(\"./logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"_lr=\" + str(lr) + \"_epochs=\" + str(epochs), session.graph)\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        for epoch in range(0, epochs):\n",
    "            if ((epoch + 1) % print_rate) == 0:\n",
    "                print(\"error: \" + str(session.run(error)))\n",
    "      \n",
    "            writer.add_summary(session.run(summary), epoch)\n",
    "            session.run(update_model)\n",
    "\n",
    "        params = session.run(params)\n",
    "\n",
    "        writer.close()\n",
    "    session.close()\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grafo del módelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![text](graphs/model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscaremos un buen learning rate y epoch para nuestro módelo, dependiendo si empizan a diverger o que tan rápido disminuye el error iremos cambiando los parámetros a probar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_hyper_parmas(lrs, epochs=1000):\n",
    "    print_rate = epochs / 5\n",
    "    for lr in lrs:\n",
    "        print(\"lr=\" + str(lr))\n",
    "        gradient_descent(x, y, epochs, lr, print_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "lr=0.0001\nerror: 5088.956758291787\nerror: 2162.742408269533\nerror: 1575.0080102649333\nerror: 1456.660140225012\nerror: 1432.5294785144506\nlr=0.0005\nerror: 1432.3470514335775\nerror: 1424.2614773656267\nerror: 1421.9446667905006\nerror: 1419.6515940904962\nerror: 1417.3802969582684\nlr=0.0009\nerror: 1424.7427929227767\nerror: 1420.5752834939058\nerror: 1416.4867205366022\nerror: 1412.467777671251\nerror: 1408.5172694029434\n"
    }
   ],
   "source": [
    "test_hyper_parmas([0.0001, 0.0005, 0.0009])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![text](graphs/000x.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al parecer un learning rate más alto hace converger el error más rapido, entonces probaremos con valores mayores a los anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "lr=0.001\nerror: 1424.2728454219214\nerror: 1419.6628965028528\nerror: 1415.141603446656\nerror: 1410.705772169294\nerror: 1406.353787266486\nlr=0.005\nerror: 1406.437968313122\nerror: 1385.8717745435767\nerror: 1367.1773640259707\nerror: 1350.1843808557787\nerror: 1334.737973666289\nlr=0.009\nerror: 1389.9060411224264\nerror: 1356.8491885187395\nerror: 1329.0098754317455\nerror: 1305.564589746283\nerror: 1285.819798660553\n"
    }
   ],
   "source": [
    "test_hyper_parmas([0.001, 0.005, 0.009])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![text](graphs/00x.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este caso parece similar al anterior, entonces probaremos con valores más grandes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "lr=0.01\nerror: 1385.965144830706\nerror: 1350.257662665267\nerror: 1320.7547398468257\nerror: 1296.3782674089744\nerror: 1276.2374694219363\nlr=0.05\nerror: 67490.81733677507\nerror: 245155.79344382486\nerror: 899881.6757441885\nerror: 3312015.2022008067\nerror: 12198522.149722412\nlr=0.09\nerror: 6.41440343111138e+169\nerror: inf\nerror: inf\nerror: nan\nerror: nan\n"
    }
   ],
   "source": [
    "test_hyper_parmas([0.01, 0.05, 0.09])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al parecer con valores mayores a 0.5 el error del módelo empiza a diverger, por lo que probaremos con valores entre 0.1 y 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "lr=0.01\nerror: 1385.965144830706\nerror: 1350.257662665267\nerror: 1320.7547398468257\nerror: 1296.3782674089744\nerror: 1276.2374694219363\nlr=0.02\nerror: 1350.4043719133924\nerror: 1296.4678508176912\nerror: 1259.650292170172\nerror: 1234.5182926042671\nerror: 1217.3629616865508\nlr=0.03\nerror: 1320.9845254064558\nerror: 1259.7042915902425\nerror: 1225.1486390011335\nerror: 1205.6628594683643\nerror: 1194.6749146445593\nlr=0.04\nerror: 1296.6473439311007\nerror: 1234.582181464807\nerror: 1205.6731486973038\nerror: 1192.2077497143168\nerror: 1185.9357664477277\n"
    }
   ],
   "source": [
    "test_hyper_parmas([0.01, 0.02, 0.03, 0.04])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![text](graphs/0x.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "lr=0.041\nerror: 1294.4580369350901\nerror: 1232.5569242631477\nerror: 1204.2703316278119\nerror: 1191.3443713602164\nerror: 1185.4376702246857\nlr=0.045\nerror: 1286.104701531549\nerror: 1225.1851942103697\nerror: 1199.397016379246\nerror: 1188.480478391776\nerror: 1183.8593375569203\nlr=0.049\nerror: 1278.3680588506857\nerror: 1218.8555896826397\nerror: 1195.5207753152222\nerror: 1186.3702850213838\nerror: 1182.7820210949678\n"
    }
   ],
   "source": [
    "test_hyper_parmas([0.041, 0.045, 0.049])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![text](graphs/04x.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque al principio el error con 0.49 no disminuye tan rápido al final es el que más disminuye de los 3, así que nos quedaremos con 0.49."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "lr=0.049\nerror: 1218.8555896826397\nerror: 1186.3702850213838\nerror: 1181.3749229404254\nerror: 1180.6067712305526\nerror: 1180.4886502535705\n"
    }
   ],
   "source": [
    "test_hyper_parmas([0.049], 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "lr=0.049\nerror: 1180.4886502535705\nerror: 1180.4671876290395\nerror: 1180.4671857836718\nerror: 1180.467185783514\nerror: 1180.4671857835122\n"
    }
   ],
   "source": [
    "test_hyper_parmas([0.049], 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "lr=0.049\nerror: 1186.3702850213838\nerror: 1180.6067712305526\nerror: 1180.4704864390233\nerror: 1180.4672638312393\nerror: 1180.4671876290395\n"
    }
   ],
   "source": [
    "test_hyper_parmas([0.049], 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "error: 1278.3680588506857\nerror: 1218.8555896826397\nerror: 1195.5207753152222\nerror: 1186.3702850213838\nerror: 1182.7820210949678\nerror: 1181.3749229404254\nerror: 1180.8231449059454\nerror: 1180.6067712305526\nerror: 1180.5219226782785\nerror: 1180.4886502535705\nerror: 1180.4756028388986\nerror: 1180.4704864390233\nerror: 1180.4684800991968\nerror: 1180.4676933351448\nerror: 1180.4673848142916\nerror: 1180.4672638312393\nerror: 1180.4672163890684\nerror: 1180.4671977851442\nerror: 1180.4671904898205\nerror: 1180.4671876290395\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[ 45.43444887],\n       [-96.19740908]])"
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "gradient_descent(x, y, 4000, 0.049, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se demostró que un learning rate de 0.49 es bastante rápido en converger al minimo error, aunque podríamos encontrar valores mejores entre 0.0491 y 0.049, pero considero que 0.49 es lo suficientemente bueno. Usando el learning rate de 0.49 el error llega rapidamente a 1180, y después de 4000 iteraciones el valor del error no baja de 1180.4671, por lo que considero que agregar más epochs no hará una gran diferencia y/o no valdría la pena.\n",
    "\n",
    "Entonces los parametros del módelo quedarían en 45.2898101 y -95.27101687, con los hyper parametros 0.49 y 4000"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}